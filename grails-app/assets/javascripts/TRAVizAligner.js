/*

Copyright (C) 2014, Stefan Jänicke.

Permission is hereby granted, free of charge, to any person obtaining a
copy of this software and associated documentation files (the "Software"),
to deal in the Software without restriction, including without limitation
the rights to use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software, and to permit persons to whom the
Software is furnished to do so, subject to the following conditions:

1. The above copyright notice and this permission notice shall be included
in all copies or substantial portions of the Software.

2. It is prohibited to remove, hide or modify any visual copyright notice
generated by this Software.

3. When using screenshots of any part of the visual output generated by
this Software for presentations or on websites the following link MUST
be clearly visible for the beholder: http://traviz.vizcovery.org

4. When using screenshots of any part of the visual output generated by
this Software in publications, the following reference MUST be inserted: 

S. Jänicke, A. Geßner, M. Büchler and G. Scheuermann (2014). Visualizations
for Text Re-use. In Proceedings of the 5th International Conference on
Information Visualization Theory and Applications, IVAPP 2014, pages 59–70.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

(Fair Academic License (FAL), http://vizcovery.org/fal.html)

*/

/**
 * -------------------------------------------------------
 * CLASS TRAVizAligner 
 * -------------------------------------------------------
 * implementation of an own sentence alignment algorithm
 * requires the graph and the configuration object
 */
function TRAVizAligner(graph,config){
	this.graph = graph;
	this.config = config;
	var cloudList = [];
}

/**
 * normalizes the given <sentence> if configured; otherwise, only multiple whitespaces are removed
 */
TRAVizAligner.prototype.normalize = function(sentence){
	sentence = $("<p>"+sentence+"</p>").text();
	if( this.config.options.normalize ){
		sentence = sentence.toLowerCase();
		sentence = sentence.replace(/--/g, "");
		sentence = sentence.replace(/,/g, "");
		sentence = sentence.replace(/\./g, "");
		sentence = sentence.replace(/;/g, "");
		sentence = sentence.replace(/:/g, "");
		sentence = sentence.replace(/\(/g, "");
		sentence = sentence.replace(/\)/g, "");
		sentence = sentence.replace(/\[/g, "");
		sentence = sentence.replace(/\]/g, "");
		sentence = sentence.replace(/\'/g, "");
		sentence = sentence.replace(/\"/g, "");
		sentence = sentence.replace(/´/g, "");
		sentence = sentence.replace(/`/g, "");
		sentence = sentence.replace(/“/g, "");
		sentence = sentence.replace(/”/g, "");
		if( sentence.lastIndexOf(" ") == sentence.length - 1 ){
			sentence = sentence.substring(0,sentence.length-1);
		}
	}
	sentence = sentence.replace(/  /g, " ");
	return sentence;
};

/**
 * core component of the sentence alignment
 * a scoring procedure weights token pairs dependent on the number of occurrences
 * the vertices of a token pair are merged, if it does not produces a cycle in the graph
 */
TRAVizAligner.prototype.alignSentences = function(sentences){
	var sal = this;
	var words = [];
	var wordVertices = [];
	var tokenized = [];
	var lastVertex = undefined;
	var wordlist = [];
	var preferenceMerge = [];
	
	
	
	
	
	var tokenizedPre = [];
	for( var i=0; i<sentences.length; i++ ){
		var sentence = this.normalize(sentences[i]);
		var tokens = sentence.split(" ");
		tokenizedPre.push(tokens);
	}
	
	//speichere alle Kapitelnummern-gleichnisse in einer Liste
	var chapterBools = [];
	var chapterIterator = [];
	for( var i=0; i<tokenizedPre.length; i++ ){
		chapterBools[i] = tokenizedPre[i][0] == "1"
		chapterIterator[i] = 0;
	}
	console.log(chapterBools);
	
	var combo = 0;
	
	//Für alle existierenden Kapitel i{
	for (var i = 1; i < 799; i++)
	{
		var chapter = "" + i;
		var nextChapter = "" + (i+1);
		var fuse = true;
		
	
		//Lass alle niedrigsten Kapitel (Kapitel i) um eins hochzählen
		
		for( var j=0; j<tokenizedPre.length; j++ ){
			if (chapterBools[j] == true && tokenizedPre[j].length-1 > chapterIterator[j]) {
				chapterIterator[j]++;
			}
			if (chapterBools[j] != (tokenizedPre[j][chapterIterator[j]] == nextChapter))
			{
				fuse = false;
			}
			//chapterBools[j] = tokenizedPre[i][0] == "1"
			
		}
		
		//WENN die Gleichnisse exakt so sind wie im vorherigen Schritt und nicht alle FALSCH: Verschmelze Seiten i und i-1
		if (fuse) 
		{
			fuse = false;
			for( var j=0; j<tokenizedPre.length; j++ )
			{
				if (chapterBools[j] == true) fuse = true;
			}
			if (fuse) 
			{
				combo++;
				//console.log("fuse " + chapter + " and " + nextChapter + " and Combo=" + combo);
				for( var j=0; j<tokenizedPre.length; j++ )
				{
					if (chapterBools[j] == true)
					{
						
						//Fuse 'em
						tokenizedPre[j][chapterIterator[j]-1] = "";
						if (combo == 1) {
							tokenizedPre[j][chapterIterator[j]] =  chapter + "-" + nextChapter;
						} else {
							tokenizedPre[j][chapterIterator[j]] =  "" + (i - combo + 1) + "-" + nextChapter;
						}
						
						
					}
				}
			}
			else
			{
				combo = 0;
			}
			
		} //SONST: Merke dir die neuen Gleichnisse
		else 
		{
			combo = 0;
			//console.log("don't fuse " + chapter);
			for( var j=0; j<tokenizedPre.length; j++ ){
				chapterBools[j] = tokenizedPre[j][chapterIterator[j]] == nextChapter;
			}
			//console.log(chapterBools);
		}
	}
	//}
	
	var sentencesNew = [];
	for( var i=0; i<tokenizedPre.length; i++ ){
		sentencesNew.push("");
		for( var j=0; j<tokenizedPre[i].length; j++ ){
			if ( tokenizedPre[i][j] != "")
				sentencesNew[i] += tokenizedPre[i][j] + " ";
		}
	}
	
	
	for( var i=0; i<sentences.length; i++ ){
		var sword = [];
		lastVertex = undefined;
		var sentence = this.normalize(sentencesNew[i]);
		var tokens = sentence.split(" ");
		var t = [];
		for( var j=0; j<tokens.length; j++ ){
			var token = tokens[j];
			var contentToken = tokens[j];
			var id = false;
			if( token.indexOf("<>") != -1 ){
				id = token.substring(1,token.indexOf('>'));
				contentToken = token.substring(token.indexOf('>')+1);
				contentToken = contentToken.substring(0,contentToken.indexOf('<'));
				token = token.substring(0,token.indexOf('>')+1)+"<>";
			}
			var word = {
				id: i+"-"+j,
				word: token,
				sid: i,
				wid: j,
				gid: words.length
			};
			words.push(word);
			sword.push(word);
			t.push(word);
			var v = new TRAVizVertex(this.graph,this.config.getVertexIndex(),token);
			if( id ){
				v.preferenceId = id;
				if( typeof preferenceMerge[id] == "undefined" ){
					preferenceMerge[id] = { vertices:[v], tokens: [contentToken] };
				}
				else {
					preferenceMerge[id].vertices.push(v);
					preferenceMerge[id].tokens.push(contentToken);
				}
			}
			v.sources.push({
				sourceId: i,
				token: token
			});
			this.graph.addVertex(v);
			if( typeof lastVertex != 'undefined' ){
				lastVertex.addSuccessor(v.index);
				v.addPredecessor(lastVertex.index);
			}
			lastVertex = v;
			wordVertices[word.id] = v;
		}
		wordlist.push(sword);
		tokenized.push(t);
	}
	var sortBySize = function(s1,s2){
		if( s1.length > s2.length ){
			return -1;
		}
		if( s1.length == s2.length ){
			return 0;
		}
		return 1;
	}
	
	
	
	//console.log("Start finding swapped words");
	//window.alert("hello");
	var cloudList = [];
	var makeCloud = function(i,u,j,w){
		//console.log("match1");
		if (tokenizedCopy[i][u].word != "CLOUD" && tokenizedCopy[i][u+1].word != "CLOUD")
		{
			tokenizedCopy[i][u].word = "CLOUD";
			tokenizedCopy[i][u+1].word = "CLOUD";
			//tokenizedCopy[i][u+1].word = "DELETETHIS";
			//tokenized[i].splice(u+1,1);
			wordVertices[tokenized[i][u].id].cloudify();
			wordVertices[tokenized[i][u].id].skipNext();
			if (typeof tokenized[i][u+2] != 'undefined'){
				console.log(typeof tokenized[i][u+2]);
				wordVertices[tokenized[i][u+2].id].skipPrevious();
			}
			//wordVertices[tokenized[i][u+1].id] = wordVertices[tokenized[i][u].id];
			wordVertices[tokenized[i][u+1].id].cloudify();
			wordVertices[tokenized[i][u+1].id].predecessors = [];
			wordVertices[tokenized[i][u+1].id].successors = [];
			//sal.graph.removeVertex(wordVertices[tokenized[i][u+1].id].index);
		}
		
		if (tokenizedCopy[j][w].word != "CLOUD" && tokenizedCopy[j][w-1].word != "CLOUD") 
		{
			tokenizedCopy[j][w].word = "CLOUD";
			tokenizedCopy[j][w-1].word = "CLOUD";
			//tokenizedCopy[j][w-1].word = "DELETETHIS";
			wordVertices[tokenized[j][w].id].cloudify();
			wordVertices[tokenized[j][w].id].skipPrevious();
			wordVertices[tokenized[j][w-2].id].skipNext();
			//wordVertices[tokenized[j][w-1].id] = wordVertices[tokenized[j][w].id];
			wordVertices[tokenized[j][w-1].id].cloudify();
			wordVertices[tokenized[j][w-1].id].predecessors = [];
			wordVertices[tokenized[j][w-1].id].successors = [];
		}
		
			//tokenized[j].splice(w-1,1);
		/*
		wordVertices[tokenized[i][u].id].token = "CLOUD1";
		wordVertices[tokenized[j][w].id].token = "CLOUD1";
		wordVertices[tokenized[i][u+1].id].token = "CLOUD1";
		wordVertices[tokenized[j][w-1].id].token = "CLOUD1";
		*/
		
		
		/*
		this.graph.vertexMap[2].sources[0].token = "CLOUD";
		this.graph.vertexMap[3].sources[0].token = "CLOUD";
		this.graph.vertexMap[6].sources[0].token = "CLOUD";
		this.graph.vertexMap[7].sources[0].token = "CLOUD";
		*/
	}
	
	var tokenizedCopy = tokenized.slice(0);
	var wordVerticesCopy = wordVertices.slice(0);
	
	for( var i=0; i<tokenized.length-1; i++ ){
		for( var j=i+1; j<tokenized.length; j++ ){
			//console.log(tokenized[i][0]);
			//console.log(tokenized[j][0]);
			//console.log(wordVertices);
			//var matches = this.pairAlignment(tokenized[i],tokenized[j],[]);
			//if( matches.length == 0 ){
			//	continue;
			//}						
			for( var u=1; u<tokenized[i].length-1; u++ ){
				for( var w=2; w<tokenized[j].length-0; w++ ){
					if (tokenized[i][u].word == tokenized[j][w].word) {
						if (tokenized[i][u+1].word == tokenized[j][w-1].word) {
							if (tokenized[i][u-1].word == tokenized[j][w-2].word) {
								if ((typeof tokenized[i][u+2] == 'undefined' && typeof tokenized[j][w+1] == 'undefined') || tokenized[i][u+2].word == tokenized[j][w+1].word) {
									//makeCloud(i,u,j,w);
									var ary = [4]
									ary[0] = i;
									ary[1] = u;
									ary[2] = j;
									ary[3] = w;
									cloudList.push(ary);
								}
							}
						}
					}
				}
			}
			
			
			
		}
	}
	
	for ( var i = 0; i < cloudList.length; i++ ){
		//makeCloud(cloudList[i][0],cloudList[i][1], cloudList[i][2], cloudList[i][3]);
	}
	
	
	
	
	/*
	
	
	//speichere alle Kapitelnummern-gleichnisse in einer Liste
	var chapterBools = [];
	var chapterIterator = [];
	for( var i=0; i<tokenized.length; i++ ){
		chapterBools[i] = tokenized[i][0].word == "1"
		chapterIterator[i] = 0;
	}
	console.log(chapterBools);
	
	var combo = 0;
	
	//Für alle existierenden Kapitel i{
	for (var i = 1; i < 799; i++)
	{
		var chapter = "" + i;
		var nextChapter = "" + (i+1);
		var fuse = true;
		
	
		//Lass alle niedrigsten Kapitel (Kapitel i) um eins hochzählen
		
		for( var j=0; j<tokenized.length; j++ ){
			if (tokenized[j][chapterIterator[j]].word == chapter && tokenized[j].length-1 > chapterIterator[j]) {
				chapterIterator[j]++;
			}
			if (chapterBools[j] != (tokenized[j][chapterIterator[j]].word == nextChapter))
			{
				fuse = false;
			}
			//chapterBools[j] = tokenized[i][0].word == "1"
			
		}
		
		//WENN die Gleichnisse exakt so sind wie im vorherigen Schritt und nicht alle FALSCH: Verschmelze Seiten i und i-1
		if (fuse) 
		{
			fuse = false;
			for( var j=0; j<tokenized.length; j++ )
			{
				if (chapterBools[j] == true) fuse = true;
			}
			if (fuse) 
			{
				combo++;
				console.log("fuse " + chapter + " and " + nextChapter + " and Combo=" + combo);
				for( var j=0; j<tokenized.length; j++ )
				{
					if (chapterBools[j] == true)
					{
						/*
						if (wordVertices[tokenized[j][chapterIterator[j]].id].successors.length > 0 )
						{
							console.log(wordVertices[tokenized[j][chapterIterator[j]].id]);
							
							
						}
						
						wordVertices[tokenized[j][chapterIterator[j]].id].skipPrevious();
						wordVertices[tokenized[j][chapterIterator[j]-(2)].id].skipNext();
							
						//tokenized[j][chapterIterator[j]-1].word = "FUSE"
						//tokenized[j][chapterIterator[j]].word = "FUSE"
						
						

						wordVertices[tokenized[j][chapterIterator[j]-1].id].predecessors = [];
						wordVertices[tokenized[j][chapterIterator[j]-1].id].successors = [];
						
						
						
						
					}
				}
			}
			else
			{
				combo = 0;
			}
			
		} //SONST: Merke dir die neuen Gleichnisse
		else 
		{
			combo = 0;
			console.log("don't fuse " + chapter);
			for( var j=0; j<tokenized.length; j++ ){
				chapterBools[j] = tokenized[j][chapterIterator[j]].word == nextChapter;
			}
			console.log(chapterBools);
		}
	}
	//}
	
	
	
	*/
	
	

	var pairs = [];
	var wordMatches = [];
	var nodes = [];
	var assignments = [];
	for( var i=0; i<words.length; i++ ){
		wordMatches.push([]);
		nodes.push(false);
		assignments.push(false);
	}
	for( var i=0; i<tokenized.length-1; i++ ){
		for( var j=i+1; j<tokenized.length; j++ ){
			var matches = this.pairAlignment(tokenized[i],tokenized[j],[]);
			if( matches.length == 0 ){
				continue;
			}
			matches.sort(sortBySize);
			var ms = "";
			for( var k=0; k<matches[0].length; k++ ){
				pairs.push({
					pair: matches[0][k],
					value: 2
				});
				var w1 = matches[0][k].w1;
				var w2 = matches[0][k].w2;
				wordMatches[w1.gid].push(w2);
				wordMatches[w2.gid].push(w1);
			}
		}
	}
	if( this.config.options.optimizeAlignment ){
		for( var i=0; i<pairs.length; i++ ){
			var w1 = pairs[i].pair.w1;
			var w2 = pairs[i].pair.w2;
			for( var j=0; j<wordMatches[w1.gid].length; j++ ){
				if( wordMatches[w1.gid][j] == w2 ){
					continue;
				}
				for( var k=0; k<wordMatches[w2.gid].length; k++ ){
					if( wordMatches[w2.gid][k] == w1 ){
						continue;
					}
					if( wordMatches[w1.gid][j] == wordMatches[w2.gid][k] ){
						pairs[i].value++;
					}
				}				
			}
		}
		var sortBySize2 = function(p1,p2){
			if( p1.value > p2.value ){
				return -1;
			}
			if( p1.value == p2.value ){
				return 0;
			}
			return 1;
		}
		pairs.sort(sortBySize2);
	}
	for( var i=0; i<preferenceMerge.length; i++ ){
		for( var j=0; j<preferenceMerge[i].vertices.length; j++ ){
			preferenceMerge[i].vertices[j].token = preferenceMerge[i].tokens[j];
		}
	}
	var checkMerge = function(w1,w2){
		var v1 = sal.graph.getVertex(wordVertices[w1.id].index), v2 = sal.graph.getVertex(wordVertices[w2.id].index);
		if( v1 == v2 ){
			return;
		}
		var v = sal.graph.isAcyclicFromVertex(v1,v2);
		if( v ){
			for( var i=0; i<words.length; i++ ){
				if( wordVertices[words[i].id] == v1 || wordVertices[words[i].id] == v2 ){
					wordVertices[words[i].id] = v;
				}
			}
		}
	}
	if( preferenceMerge.length > 0 ){
		for( var i=0; i<pairs.length; i++ ){
			var v1 = sal.graph.getVertex(wordVertices[w1.id].index), v2 = sal.graph.getVertex(wordVertices[w2.id].index);
			if( v1.preferenceId && v1.preferenceId == v2.preferenceId ){
				checkMerge(pairs[i].pair.w1,pairs[i].pair.w2);
				pairs[i].mark = true;
			}
		}
	}
	for( var i=0; i<pairs.length; i++ ){
		if( !pairs[i].mark ){
			checkMerge(pairs[i].pair.w1,pairs[i].pair.w2);
		}
	}
	var sentencePaths = [];
	for( var i=0; i<wordlist.length; i++ ){
		var sp = [this.graph.startVertex];
		for( var j=0; j<wordlist[i].length; j++ ){
			var v = wordVertices[wordlist[i][j].id];
			if( j == 0 ){
				this.graph.startVertex.addSuccessor(v.index);
				v.addPredecessor(this.graph.startVertex.index);
			}
			if( j == wordlist[i].length-1 ){
				v.addSuccessor(this.graph.endVertex.index);						
				this.graph.endVertex.addPredecessor(v.index);
			}
			sp.push(v);
		}
		sp.push(this.graph.endVertex);
		sentencePaths.push(sp);
	}
	return sentencePaths;
};

TRAVizAligner.prototype.getCloud = function(){
	
}

/**
 * returns the edit distance for two given words <a> and <b>
 * thankfully taken from: http://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance
 */
TRAVizAligner.prototype.getEditDistance = function(a,b){
	if( a.length === 0 ){
		return b.length;
	}
	if( b.length === 0 ){
		return a.length;
	} 
	var matrix = [];
	var i;
	for( i=0; i<=b.length; i++ ){
		matrix[i] = [i];
	}
	var j;
	for( j=0; j<=a.length; j++ ){
		matrix[0][j] = j;
	}
	for( i=1; i<=b.length; i++ ){
		for( j=1; j<=a.length; j++ ){
			if( b.charAt(i-1) == a.charAt(j-1) ){
				matrix[i][j] = matrix[i-1][j-1];
			}
			else {
				matrix[i][j] = Math.min(matrix[i-1][j-1]+1,Math.min(matrix[i][j-1]+1,matrix[i-1][j]+1));
			}
		}
	}
	return matrix[b.length][a.length];
};

/**
 * returns all possible paths with aligned tokens in the correct order between sentences <s1> and <s2>
 */
TRAVizAligner.prototype.pairAlignment = function(s1,s2){
	var matches = [];
	for( var i=0; i<s1.length; i++ ){
		matches.push([]);
		for( var j=0; j<s2.length; j++ ){
			if( this.config.options.editDistance ){
				var ld = this.getEditDistance(s1[i].word,s2[j].word);
				var red = 2*ld / (s1[i].word.length+s2[j].word.length);
				if( red <= this.config.options.editDistance ){
					matches[i].push(s2[j]);
				}
			}
			else if( s1[i].word == s2[j].word ){
				matches[i].push(s2[j]);
			}
		}
	}
	var paths = [];
	for( var i=0; i<matches.length; i++ ){
		var newPaths = [];
		var addPath = function(path1){
			var lNode1 = path1[path1.length-1];
			var found = false;
			var np = [];
			for( var j=newPaths.length; j>0; j-- ){
				var path2 = newPaths[j-1];
				var lNode2 = path2[path2.length-1];
				if( lNode1.w2 == lNode2.w2 && path1.length != path2.length ){
					if( path1.length <= path2.length ){
						np.push(path2);
						found = true;
					}
				}
				else if( lNode1.w2 == lNode2.w2 && path1.length == path2.length ){
					np.push(path2);
					found = true;
				}
				else {
					np.push(path2);
				}
			}
			if( !found ){
				np.push(path1);
			}
			newPaths = np;
		}
		for( var k=0; k<paths.length; k++ ){
			var path = paths[k];
			addPath(path);
			var lNode = path[path.length-1].w2;
			for( var j=0; j<matches[i].length; j++ ){
				var node = matches[i][j];
				if( node.wid > lNode.wid ){
					addPath(path.concat([{ w1: s1[i], w2: node}]));
				}
			}
		}
		for( var j=0; j<matches[i].length; j++ ){
			addPath([{ w1: s1[i], w2: matches[i][j]}]);
		}
		paths = newPaths;
	}
	return paths;
};

/**
 * computes the shortest strongest path in the graph structure
 * required to subsequently place the paths in form of layers
 */
TRAVizAligner.prototype.strongestShortestPath = function(s){
	var strength = 0, length = 1000000;
	var path = undefined;
	for( var i=0; i<s.successors.length; i++ ){
		var pi = [s];
		var si = s.count;
		var li = 1;
		var vertex = this.graph.getVertex(s.successors[i]);
		pi.push(vertex);
		if( !vertex.traced ){
			var vs = vertex.successors;
			si += vertex.count;
			while( vs.length > 0 ){
				var lc = this.graph.getVertex(vs[0]).count;
				var v = this.graph.getVertex(vs[0]);
				for( var j=1; j<vs.length; j++ ){
					if( this.graph.getVertex(vs[j]).count > lc ){
						lc = this.graph.getVertex(vs[j]).count;
						v = this.graph.getVertex(vs[j]);
					}
				}
				li++;
				pi.push(v);
				if( !v.traced ){
					si += lc;
					vs = v.successors;
				}
				else {
					vs = [];
				}
			}
		}
		if( li < length || li == length && si > strength ){
			length = li;
			strength = si;
			path = pi;
		}
	}
	return {
		strength: strength,
		length: length,
		path: path
	}
};

/**
 * computes all shortest strongest paths with a given <sentencePath> that is placed on layer 0
 */
TRAVizAligner.prototype.getPaths = function(sentencePath){
	for( var i=0; i<this.graph.vertices.length; i++ ){
		this.graph.vertices[i].traced = false;
	}
	var p = sentencePath;
	for( var i=0; i<p.length; i++ ){
		p[i].traced = true;
	}
	var paths = [p];
	var traverse = true;
	var runs = 0;
	while( traverse ){
		runs++;
		traverse = false;
		var c = undefined;
		for( var i=0; i<this.graph.vertices.length; i++ ){
			var v = this.graph.vertices[i];
			if( v.traced ){
				for( var k=0; k<v.successors.length; k++ ){
					if( !this.graph.getVertex(v.successors[k]).traced ){
						var p = this.strongestShortestPath(this.graph.getVertex(v.successors[k]));
						p.path.splice(0,0,v);
						if( typeof c == "undefined" || c.length > p.length || 
							c.length == p.length && p.strength > c.strength ){
							c = p;
						}
					}
				}
			}
			else {
				traverse = true;
			}
		}
		if( typeof c != "undefined" ){
			for( var i=0; i<c.path.length; i++ ){
				c.path[i].traced = true;
			}
			paths.push(c.path);
		}
	}
	return paths;
};

/**
 * computes all shortest strongest paths with a given <sentencePath> that is placed on layer 0
 */
TRAVizAligner.prototype.getPathsByEdition = function(sentencePath,sentencePaths){
	var spcopy = [];
	for( var i=0; i<sentencePaths.length; i++ ){
		if( sentencePath != sentencePaths[i] ){
			spcopy.push(sentencePaths[i]);
		}
	}
	for( var i=0; i<this.graph.vertices.length; i++ ){
		this.graph.vertices[i].traced = false;
	}
	var p = sentencePath;
	for( var i=0; i<p.length; i++ ){
		p[i].traced = true;
	}
	var paths = [p];
	while( spcopy.length > 0 ){
		var overlap = false, id = false, strength = false;
		for( var i=0; i<spcopy.length; i++ ){
			var ol = 0;
			var str = 0;
			for( var j=0; j<spcopy[i].length; j++ ){
				if( spcopy[i][j].traced ){
					ol++;
				}
				else {
					str += spcopy[i][j].count;
				}
			}
			if( !overlap || ol > overlap || ol == overlap && str > strength ){
				overlap = ol;
				id = i;
				strength = str;
			}
		}
		var pi = false;
		for( var i=0; i<spcopy[id].length; i++ ){
			if( !pi && !spcopy[id][i].traced ){
				pi = [spcopy[id][i-1],spcopy[id][i]];
			}
			else if( pi && spcopy[id][i].traced ){
				pi.push(spcopy[id][i]);
				paths.push(pi);
				pi = false;
			}
			else if( pi && !spcopy[id][i].traced ){
				pi.push(spcopy[id][i]);
			}
			spcopy[id][i].traced = true;
		}
		if( pi ){
			paths.push(pi);
		}
		spcopy.splice(id,1);
	}
	return paths;
};
